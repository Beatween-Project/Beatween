# 4/22 정리

### 1. 주제 선정

- 밴드 합주를 위한 앱

1. 악보 생성

    - 유트브 링크, 또는 음원 파일을 넣으면 자동으로 악기를 분리해서 파트별 악보 생성

    - pdf를 업로드 하는 기능도 생각중중

2. 악보 동시 재생

    - 밴드 내 악보 공유 or 그룹화?를 통해 악보 동시 재생 -> 연주되는 부분 하이라이트 or 막대바로 표시, 자동 페이지 넘김

3. 악보 편집

    - 내 라이브러리에 등록된 악보들을 편집 가능

4. 개인 연습 모드 (주요 기능 x)

    - 다른 악기들 자동 재생

5. 일정 공유 (주요 기능 x)

    - 캘린더 앱과 연동

6. 커뮤니티 (주요 기능 x)

    - 구인/홍보/공유 게시판

### 기술 스택 선정

- 현재 미정! 조사만 했습니다. 추후 논의 필요

- 웹 vs 앱

보통 **같은 조건이면 네이티브 앱이 더 빠릅니다.**

| 구간 | 왜 앱이 유리한가? |
| --- | --- |
| **콜드‑스타트** | 코드가 이미 단말에 설치돼 있어 **다운로드·파싱 단계(HTML/JS/CSS)가 없음** |
| **렌더링** | 네이티브 위젯‑트리 → GPU까지 직통.웹은 DOM‑트리 구성‑→‑JS 실행‑→‑레이아웃/리플로우가 필요 |
| **브리지 호출** | 앱은 자바/Kotlin·Swift 코드가 그대로 실행.웹은 JS ↔ 네이티브 브리지(Chromium V8 등) 왕복 비용 발생 |
| **센서·실시간 I/O** | 카메라·BLE·WebRTC 등: 웹은 권한 프롬프트·추가 래퍼 필요 → 지연 수 ms 증가 |

**숫자로 보면** (중간급 안드로이드·4G, 동일 API 서버 기준)

- 앱 콜드‑스타트 TTI: **~700 – 1500 ms**
- 모바일 웹 FCP + JS 실행: **~1.5 – 3 초**
- 후속 API 요청 이후 화면 갱신: 차이 **수 10 ms 내외** (JS bundle 최적화했을 때)

> 따라서 “최소 지연”을 목표로 하면 네이티브 앱이 기본 선택이고,
> 
> 
> 웹은 배포 주기·검색 노출·설치 장벽을 낮추는 것이 주된 장점입니다.
> 

단, **경량 PWA + HTTP/3 + Edge 캐시**처럼 극단적으로 튜닝하면 체감 차이가 거의 사라질 수 있습니다.

- 서버 시간, 로컬 시간은 웹, 앱 모두에서 비교 가능

“동시에 연주” 같이 **왕복 < 30 ms**를 노리는 서비스라면

**네이티브‑앱(데스크톱·모바일)** 쪽이 본질적으로 더 유리합니다

| 항목 | 브라우저(WebRTC + Web Audio) | 네이티브(CoreAudio / ASIO / Oboe …) |
| --- | --- | --- |
| **오디오 캡처·재생 버퍼** | 고정 128‑frame(≈ 2.9 ms @ 44.1 kHz) `AudioWorklet` 이상 불가 → 내부 스레드 스케줄링 지터 5‑10 ms 추가 [Chrome for Developers](https://developer.chrome.com/blog/audio-worklet-design-pattern?utm_source=chatgpt.com) | iOS 64‑frame, Android 48‑frame(Oboe `LowLatency`) 등 **1‑3 ms** 단위로 설정 가능 [Android Developers](https://developer.android.com/games/sdk/oboe/low-latency-audio?utm_source=chatgpt.com) |
| **코덱 지연** | WebRTC Opus 기본 20 ms·10 ms; 낮춰도 10 ms쯤이 한계 | Opus “restricted‑low‑delay” 5 ms frame, PCM / FLAC(무압축) 선택 가능 [Wikipedia](https://en.wikipedia.org/wiki/Opus_%28audio_format%29?utm_source=chatgpt.com) |
| **네트워크 계층** | WebRTC UDP이지만 MTU·패킷 pace 조절 권한 제한, SFU 구성 필요 | RTP/UDP·QUIC 직접 제어(패킷 길이·FEC·패킷 삭제 전략까지 튜닝) |
| **스케줄링 우선순위** | 오디오‑스레드가 탭·창 포커스에 따라 점유율 변동 | `REALTIME_AUDIO` 스케줄링 및 **전용 MMAP 버스**(Android), CoreAudio I/O thread |
| **드리프트 보정** | `performance.now()` + WebRTC RTCP XR 통계로 추정 | 모노토닉 클록(`elapsedRealtimeNanos`, `mach_absolute_time`) 직접 접근·루프백 측정 |

**=> 합계 지연**

*단말(캡처+플레이백) ≈ **15 – 25 ms** Web < **5 – 12 ms** Native*

네트워크 RTT 10 ms 내외(지리적 거리 < 500 km, 전용 회선)라면

**Native는 목표 30 ms 안에 들지만, Web은 안전 구간이 40‑50 ms 수준**이 됩니다.

---

실전 설계 가이드 (네이티브 기준)

| 레이어 | 권장 기술 & 팁 |
| --- | --- |
| **오디오 I/O** | *Desktop* : ASIO / CoreAudio, buffer 64 ↓*iOS* : RemoteIO AudioUnit, 256frame→64frame 전환*Android* : **Oboe** `setPerformanceMode(LowLatency)` |
| **코덱·전송** | Opus 5 ms CELT, 48 kHz, 128 kbps CBRUDP + RTP + 5‑10 ms **jitter buffer**앞단에 **Forward Error Correction (FEC)** 2‑frame |
| **동기화** | 최초 접속 시 4‑way ‘ping’으로 클록 오프셋 계측 → 각 패킷에 48‑kHz sample‑time 타임스탬프 부착 |
| **믹싱 아키텍처** | *≤ 6 명* : P2P mesh, 로컬 믹스*그 이상* : **SFU**(Selective‑Forwarding Unit) → 참가자별 맞춤 Jitter‑buffer 길이 |
| **대역폭 최적화** | 스테레오 48 kHz @ Opus 96 kbps → 실효 약 120 kbps/사용자영상은 분리 스트림 혹은 OBS‑NDI 대체 권장 |

도메인 레퍼런스

- **Jamulus / JackTrip / FarPlay** — 모두 UDP + Opus 5 ms & 네이티브 오디오 API
- **Web** 기반 시연 플랫폼에서 보고된 최소 왕복 ≈ 45 ms (이론 30 ms 초과) [Chrome for Developers](https://developer.chrome.com/blog/audio-worklet-design-pattern?utm_source=chatgpt.com)[Wikipedia](https://en.wikipedia.org/wiki/Opus_%28audio_format%29?utm_source=chatgpt.com)

### 불안 요소

- **ai 채보**
    - 악보 생성이 안 되면 다 무너질 수 있음
    - AI 팀원의 업무가 과중될 수 있음

→악보를 자동으로 생성해줄 수 없다면, 이것은 자동 등록하게 바꿀 수밖에 없을 듯

→악보를 생성하는 것도 문제이지만, 입문자 등은 악보바다 같은 곳에서 악보를 받아서 하는 경우가 많은데, 이럴 때 악보 pdf를 올렸을 때 그것을 순서대로 넘겨주는 게 가능할지.. 도 고민

악보에 메모 가능해야 할 것 같은 느낌

http://sound-of-pixels.csail.mit.edu/

악기 소리를.. 구분해준다..

https://gall.dcinside.com/mgallery/board/view/?id=drum&no=24143

⇒ https://feat.band/ 뭔가 구글 검색하다가 악보 보여주는 웹서비스 만든 게 있길래 놔둡니다 잘 만들었다.. 이쪽은 사용자들이 직접 악보를 등록하는 식인 것 같아요(원곡 신청 메뉴가 있음)

지피티 왈, AI가 완전히 실패하면 메트로놈·템포 표시 기능으로 최소한의 연습 툴로 전환

연습 툴로 바꾼다면 혼자 하나의 악기로 연습을 하는데 맞았나 틀렸나 실시간으로 악보에 표시해주는 서비스. 오디오 프레임마다 감지 결과를 WebSocket 또는 UI 이벤트로 전달해서 표시. 음은 피치 검출 알고리즘을 통해 확인

https://www.mule.co.kr/bbs/comm/mulein?idx=55885120&map=false&v=v

⇒melodyne 을 쓰면 단일 멜로디, 화음 연주를 midi로 변환해준다고..

https://www.mule.co.kr/bbs/info/recruit?idx=60992504&page=1&map=list&mode=list&region=&start_price=&end_price=&qf=title_legacy&qs=&category=&ct1=&ct2=&ct3=&store=&options=&soldout=&sido=&gugun=&dong=&period=6&of=wdate&od=desc&andor=and&v=v

스타트업 ‘스트라’의 ai 채보 사이트: https://stra.ai/solutions/index.html

https://www.nextunicorn.kr/company/1ac3fe1acd645ed5?tab=service

⇒연주를 해서, AI가 실력을 분석하고 악보 추천, 연주해서 올리면 합쳐서 영상 파일끼리 합친 합주 가능한 서비스, 아직 

- **합주의 real-time 초저지연 기술**
    - 악보가 자동으로 넘어가는 화면, 줄이나 마디 단위로 표시하는 것을 모두 동시에 볼 수 있어야 함
    
    - MusicXML이라면  → 바로 쓸 수 있음
    - pdf라면 → MusicXML로 변환 후 pageMap.json 생성 필요. pageMap.json은 음악적 위치를 pdf의 페이지 번호와 매핑하는 역할
    - 아래 방법은 서버 부하 없이 단말에서만 동작하는 방식
    1. P2P 연결 & 시계 동기화
        - **시그널링**(WebSocket 등)으로 ICE 후보 교환 → RTCPeerConnection ⇄ DataChannel 수립
        - **4‑way ping**으로 `offset = serverTime – (clientNow + RTT/2)` 계산
    2. 악보 캐싱
    3. 오디오 캡쳐 API를 이용해 PCM 버퍼 획득
        - PCM이란 마이크를 통해 아날로그 신호를 디지털화한 값. 실시간으로 오디오 데이터를 처리할 수 있음
        - Android(Java): `AudioRecord`, Android(C++): `Oboe`
    4. 비트, 마디를 검출해 마디 끝 시점 예측
        - DSP 라이브러리(Aubio, Essentia, librosa 포팅 등)를 이용해 Onset 검출 + 템포 추정으로 예측
    5. Tick 결정
        - Tick은 “음악적 절대 좌표”(마디·박자 단위)
        - 예측된 샘플 인덱스 → `tick = floor(sampleIndex / 샘플_per_tick)` 계산
    6. 풀 메쉬 P2P로 악보 넘기는 이벤트 전파
        - P2P DataChannel : WebRTC 프로토콜의 일부 API
    
    - https://developer.android.com/games/sdk/oboe/low-latency-audio?hl=ko

- 이미 있는 서비스 (다 Mac용)
    - https://newzik.com/en/
        - 악보 자동 동시 넘기기 해줌
    - https://www.youtube.com/watch?v=DSWzErU5qHA&ab_channel=EricMrugalaViolin
        - 악보에 메모도 되고 메트로놈도 있고.. 합주 용은 아닌 듯
    - https://www.staffpad.net/?utm_source=chatgpt.com#StaffPad
        - 작곡 앱. 직접 악보 작성,  오디오 녹음, 가져오기, 여러 악기를 이용해 악보 재생하기 등등
- **가상악기 구현**
    - 신디는 표준 스펙이 있지만 어쿠스틱 악기는 어떻게..?
    - teenage engineering - op1의 커뮤니티에 샘플이 있을 수 있음 → 하지만 갖다 써도 될지는 모르겠음
    - MuseScore
    - https://splice.com/
        - 각각의 음이 있는 게 아니라 15초 정도의 짧은 음악 리스트가 많음


### 역할 분담

- 프로젝트 설계가 나와야 가능할 것이라고 판단되어 미룸

- 현재
    - 프론트 : 서건호
    - AI : 윤혜진, 최현용
    - 백 : 백지민, 이규리, 이성희

    - AI 끝날 시 백 투입
    - 프론트 더 맡을 인원 미정
    - 인프라 이규리, 이성희 희망중

### 기타

- 악보 수정 불가 이슈 -> Lomose 라이브러리 찾아보는중인데 웹인지 앱인지 결정되고 나서 더 자세히 알아보기로 함

- 세션 분리, 채보 변환 라이브러리/AI를 더 찾아보고 튜닝하는 방법도 알아봐야 할듯

